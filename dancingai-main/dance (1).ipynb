{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da4306d1-39b5-4f22-b4f7-8e9cd460e204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\solom\\appdata\\roaming\\python\\python38\\site-packages (0.10.11)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: absl-py in c:\\users\\solom\\appdata\\roaming\\python\\python38\\site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\solom\\appdata\\roaming\\python\\python38\\site-packages (from mediapipe) (0.4.13)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mediapipe) (3.7.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mediapipe) (1.24.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\solom\\appdata\\roaming\\python\\python38\\site-packages (from mediapipe) (4.12.0.88)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\solom\\appdata\\roaming\\python\\python38\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in c:\\users\\solom\\appdata\\roaming\\python\\python38\\site-packages (from jax->mediapipe) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jax->mediapipe) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jax->mediapipe) (8.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->mediapipe) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->mediapipe) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\solom\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->mediapipe) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib->mediapipe) (6.4.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata>=4.6->jax->mediapipe) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\solom\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7295cef3-7350-4a4c-a0b2-1c5e69a5e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d01983-53bc-46f0-9fb9-d3de412f9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Create the pose object\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dab67a03-5ea0-4d4d-834d-811bba8db680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Ignoring empty frame.\")\n",
    "        continue\n",
    "\n",
    "    # Convert the BGR image to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # Process the image and detect pose\n",
    "    results = pose.process(image)\n",
    "\n",
    "    # Draw the pose annotation on the image\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # Show the final output\n",
    "    cv2.imshow('Real-Time Pose Detection', image)\n",
    "\n",
    "    # Exit with 'q' key\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e16353e-eea4-45e8-95cd-ba2444bd2209",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Release resources\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m \u001b[43mca\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ca' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally (so you see yourself like a mirror)\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Prepare two copies of the frame\n",
    "    original = frame.copy()                     # Left side: original\n",
    "    skeleton = np.zeros_like(frame)            # Right side: black background\n",
    "\n",
    "    # Convert to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    rgb_frame.flags.writeable = False\n",
    "\n",
    "    # Detect pose\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # If landmarks detected, draw them on the black skeleton image\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            skeleton,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(255,0,0), thickness=2)\n",
    "        )\n",
    "\n",
    "    # Combine original and skeleton side-by-side\n",
    "    combined = np.hstack((original, skeleton))\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow('You (Left) vs Skeleton (Right)', combined)\n",
    "\n",
    "    # Exit with 'q'\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "ca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67392047-ba7c-49a8-9289-71cd0d921968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally (so you see yourself like a mirror)\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Prepare two copies of the frame\n",
    "    original = frame.copy()                     # Left side: original\n",
    "    skeleton = np.zeros_like(frame)            # Right side: black background\n",
    "\n",
    "    # Convert to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    rgb_frame.flags.writeable = False\n",
    "\n",
    "    # Detect pose\n",
    "    results = pose.process(rgb_frame)\n",
    "\n",
    "    # If landmarks detected, draw them on the black skeleton image\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            skeleton,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(255,0,0), thickness=2)\n",
    "        )\n",
    "\n",
    "    # Combine original and skeleton side-by-side\n",
    "    combined = np.hstack((original, skeleton))\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow('You (Left) vs Skeleton (Right)', combined)\n",
    "\n",
    "    # Exit with 'q'\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# âœ… Corrected: release the camera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1320e95b-05b9-4bbc-96fa-e6201dd82642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create a socket\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  # UDP socket\n",
    "server_address = ('127.0.0.1', 5050)  # Send to Unity on localhost\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        key_indices = [0, 11, 12, 13, 14, 23, 24]\n",
    "        for idx in key_indices:\n",
    "            lm = landmarks[idx]\n",
    "            data[str(idx)] = {'x': lm.x, 'y': lm.y, 'z': lm.z}\n",
    "\n",
    "        # Convert to JSON and send\n",
    "        message = json.dumps(data).encode()\n",
    "        sock.sendto(message, server_address)\n",
    "\n",
    "    cv2.imshow(\"Pose\", frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c737b8-d6d5-42d2-9d29-783e4445adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create UDP socket\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "server_address = ('127.0.0.1', 5050)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        print(\"Pose detected âœ…\")\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        key_indices = [0, 11, 12, 13, 14, 23, 24]  # Selected joints\n",
    "\n",
    "        for idx in key_indices:\n",
    "            lm = landmarks[idx]\n",
    "            data[str(idx)] = {'x': lm.x, 'y': lm.y, 'z': lm.z}\n",
    "            print(f\"Joint {idx}: x={lm.x:.2f}, y={lm.y:.2f}, z={lm.z:.2f}\")\n",
    "\n",
    "        # Send JSON data over socket\n",
    "        message = json.dumps(data).encode()\n",
    "        sock.sendto(message, server_address)\n",
    "        print(\"Data sent to Unity ðŸš€\")\n",
    "\n",
    "    else:\n",
    "        print(\"âŒ Pose not detected. Please stand in camera view.\")\n",
    "\n",
    "    # Show the webcam frame\n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e6d0c-11cd-4a7a-b964-509f727524cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create UDP socket\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "server_address = ('127.0.0.1', 5050)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip frame to mirror image\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Original feed for the left side\n",
    "    original = frame.copy()\n",
    "\n",
    "    # Black image for the skeleton side\n",
    "    skeleton = np.zeros_like(frame)\n",
    "\n",
    "    # Convert to RGB\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        key_indices = [0, 11, 12, 13, 14, 23, 24]  # Nose, shoulders, elbows, hips\n",
    "\n",
    "        for idx in key_indices:\n",
    "            lm = landmarks[idx]\n",
    "            data[str(idx)] = {'x': lm.x, 'y': lm.y, 'z': lm.z}\n",
    "            print(f\"Joint {idx}: x={lm.x:.2f}, y={lm.y:.2f}, z={lm.z:.2f}\")\n",
    "\n",
    "        # Send JSON to Unity\n",
    "        message = json.dumps(data).encode()\n",
    "        sock.sendto(message, server_address)\n",
    "        print(\"Data sent to Unity ðŸš€\")\n",
    "\n",
    "        # Draw pose landmarks on the black image\n",
    "        mp_drawing.draw_landmarks(\n",
    "            skeleton,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
    "        )\n",
    "    else:\n",
    "        print(\"âŒ Pose not detected\")\n",
    "\n",
    "    # Combine both views side-by-side\n",
    "    combined = np.hstack((original, skeleton))\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow(\"You (Left) vs Skeleton (Right)\", combined)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e70e9-5839-433f-9598-3cd15fb7df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Load the anime face image\n",
    "face_img = cv2.imread('anime_face.png', cv2.IMREAD_UNCHANGED)\n",
    "if face_img is None:\n",
    "    print(\"âŒ Couldn't load face image. Make sure 'anime_face.png' is in the same folder.\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Resize face image\n",
    "face_img = cv2.resize(face_img, (100, 100))\n",
    "\n",
    "# Init MediaPipe\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Webcam capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    # Left view = original webcam\n",
    "    left = frame.copy()\n",
    "\n",
    "    # Right view = black canvas\n",
    "    right = np.zeros_like(frame)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "        # Draw stickman on right\n",
    "        mp_drawing.draw_landmarks(\n",
    "            right,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=4, circle_radius=4),\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=4)\n",
    "        )\n",
    "\n",
    "        # Get head (nose) landmark = index 0\n",
    "        nose = landmarks[0]\n",
    "        h, w, _ = right.shape\n",
    "        cx, cy = int(nose.x * w), int(nose.y * h)\n",
    "\n",
    "        # Overlay anime face at nose location\n",
    "        face_h, face_w, _ = face_img.shape\n",
    "\n",
    "        # Top-left corner of face image\n",
    "        x1 = cx - face_w // 2\n",
    "        y1 = cy - face_h // 2\n",
    "        x2 = x1 + face_w\n",
    "        y2 = y1 + face_h\n",
    "\n",
    "        # Ensure bounds are within image size\n",
    "        if x1 >= 0 and y1 >= 0 and x2 <= w and y2 <= h:\n",
    "            roi = right[y1:y2, x1:x2]\n",
    "            face_rgb = face_img[:, :, :3]\n",
    "            face_alpha = face_img[:, :, 3] / 255.0\n",
    "\n",
    "            for c in range(3):  # RGB channels\n",
    "                roi[:, :, c] = roi[:, :, c] * (1 - face_alpha) + face_rgb[:, :, c] * face_alpha\n",
    "\n",
    "            right[y1:y2, x1:x2] = roi\n",
    "\n",
    "    combined = np.hstack((left, right))\n",
    "    cv2.imshow(\"You (Left) | Anime Twin (Right)\", combined)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6aef28-9a7f-4ccd-9b17-afedfc8a4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Setup MediaPipe Pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Setup UDP socket for Unity\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "server_address = ('127.0.0.1', 5050)\n",
    "\n",
    "# Start Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def draw_cartoon_avatar(landmarks, img, width, height):\n",
    "    points = {}\n",
    "    for idx in [0, 11, 12, 13, 14, 23, 24]:  # Nose, shoulders, elbows, hips\n",
    "        lm = landmarks[idx]\n",
    "        x, y = int(lm.x * width), int(lm.y * height)\n",
    "        points[idx] = (x, y)\n",
    "\n",
    "    # Cartoon head\n",
    "    if 0 in points:\n",
    "        cv2.circle(img, points[0], 30, (255, 204, 102), -1)  # Face skin color\n",
    "        cv2.circle(img, points[0], 5, (0, 0, 0), -1)         # Nose\n",
    "\n",
    "    # Cartoon body (shoulders to hips)\n",
    "    if 11 in points and 12 in points:\n",
    "        cv2.line(img, points[11], points[12], (0, 255, 0), 4)\n",
    "    if 11 in points and 23 in points:\n",
    "        cv2.line(img, points[11], points[23], (0, 255, 0), 4)\n",
    "    if 12 in points and 24 in points:\n",
    "        cv2.line(img, points[12], points[24], (0, 255, 0), 4)\n",
    "\n",
    "    # Cartoon arms\n",
    "    if 11 in points and 13 in points:\n",
    "        cv2.line(img, points[11], points[13], (255, 0, 0), 4)\n",
    "    if 12 in points and 14 in points:\n",
    "        cv2.line(img, points[12], points[14], (255, 0, 0), 4)\n",
    "\n",
    "    return img\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    original = frame.copy()\n",
    "    h, w = frame.shape[:2]\n",
    "    cartoon = np.full_like(frame, 255)  # White background\n",
    "\n",
    "    # Convert to RGB\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        key_indices = [0, 11, 12, 13, 14, 23, 24]  # Select major joints\n",
    "\n",
    "        for idx in key_indices:\n",
    "            lm = landmarks[idx]\n",
    "            data[str(idx)] = {'x': lm.x, 'y': lm.y, 'z': lm.z}\n",
    "\n",
    "        # Send data to Unity\n",
    "        message = json.dumps(data).encode()\n",
    "        sock.sendto(message, server_address)\n",
    "        print(\"âœ… Sent to Unity\")\n",
    "\n",
    "        # Draw cartoon avatar\n",
    "        cartoon = draw_cartoon_avatar(landmarks, cartoon, w, h)\n",
    "    else:\n",
    "        print(\"âŒ Pose not detected\")\n",
    "\n",
    "    # Combine original and cartoon\n",
    "    combined = np.hstack((original, cartoon))\n",
    "    cv2.imshow(\"You (Left) vs Cartoon Avatar (Right)\", combined)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20eaf4-effe-4c7a-b4c1-b811dd593900",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = mp_pose.Pose(model_complexity=1, enable_segmentation=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df790b88-aa05-40b5-8f52-50108275998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for idx, lm in enumerate(results.pose_landmarks.landmark):\n",
    "    data[str(idx)] = {'x': lm.x, 'y': lm.y, 'z': lm.z}\n",
    "\n",
    "# Send full body pose\n",
    "message = json.dumps(data).encode()\n",
    "sock.sendto(message, server_address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaab77c-2386-4798-8b26-85d5f71abf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(model_complexity=1)\n",
    "\n",
    "# UDP setup\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "server_address = ('127.0.0.1', 5050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11645d3e-80e8-41f7-a90a-28de48d99e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_mesh_body(landmarks, canvas, w, h):\n",
    "    pts = [(int(lm.x * w), int(lm.y * h)) for lm in landmarks]\n",
    "    # Draw filled mesh polygons between pose connections\n",
    "    for connection in mp_pose.POSE_CONNECTIONS:\n",
    "        p1, p2 = connection\n",
    "        if p1 < len(pts) and p2 < len(pts):\n",
    "            cv2.line(canvas, pts[p1], pts[p2], (30, 144, 255), 4)\n",
    "    # Optionally fill torso\n",
    "    torso = [pts[i] for i in [11,12,23,24]]\n",
    "    cv2.fillPoly(canvas, [np.array(torso, dtype=np.int32)], (32, 178, 170))\n",
    "    return canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6679a3-a4f8-4d82-aefb-74bc0d4ce537",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "print(\"Press 'q' to quit\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w = frame.shape[:2]\n",
    "    canvas = np.zeros_like(frame)\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "        # Send all pose points\n",
    "        data = {str(i): {'x': lm.x, 'y': lm.y, 'z': lm.z}\n",
    "                for i, lm in enumerate(landmarks)}\n",
    "        sock.sendto(json.dumps(data).encode(), server_address)\n",
    "\n",
    "        # Draw mesh avatar\n",
    "        canvas = draw_mesh_body(landmarks, canvas, w, h)\n",
    "    else:\n",
    "        cv2.putText(canvas, \"No pose detected\", (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    combined = np.hstack((frame, canvas))\n",
    "    cv2.imshow(\"You (Left) vs Mesh Avatar (Right)\", combined)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b00ac-9c91-4ca7-8e8d-8aaccad18fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_face = mp.solutions.face_mesh\n",
    "\n",
    "pose = mp_pose.Pose(model_complexity=1)\n",
    "face_mesh = mp_face.FaceMesh(static_image_mode=False, max_num_faces=1)\n",
    "\n",
    "# UDP setup\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "server_address = ('127.0.0.1', 5050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c44ea-4edc-40fe-b458-956a8a0f2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_mesh_body(landmarks, canvas, w, h):\n",
    "    pts = [(int(lm.x * w), int(lm.y * h)) for lm in landmarks]\n",
    "    for connection in mp_pose.POSE_CONNECTIONS:\n",
    "        p1, p2 = connection\n",
    "        if p1 < len(pts) and p2 < len(pts):\n",
    "            cv2.line(canvas, pts[p1], pts[p2], (30, 144, 255), 4)\n",
    "    torso = [pts[i] for i in [11, 12, 24, 23] if i < len(pts)]\n",
    "    if len(torso) == 4:\n",
    "        cv2.fillPoly(canvas, [np.array(torso)], (32, 178, 170))\n",
    "    return canvas\n",
    "\n",
    "def detect_face_emoji(face_landmarks, w, h):\n",
    "    # Get upper lip and lower lip points\n",
    "    top_lip = face_landmarks.landmark[13]\n",
    "    bottom_lip = face_landmarks.landmark[14]\n",
    "    lip_dist = abs(bottom_lip.y - top_lip.y)\n",
    "\n",
    "    # Define emoji based on mouth openness\n",
    "    if lip_dist > 0.05:\n",
    "        return \"ðŸ˜®\"  # Mouth open\n",
    "    else:\n",
    "        return \"ðŸ˜Š\"  # Neutral/smile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18acd2a-ecc9-41ac-a1cc-71d182cdde46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
